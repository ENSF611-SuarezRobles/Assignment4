{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 4: Pipelines and Hyperparameter Tuning (32 total marks)\n",
    "### Due: November 22 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will be putting together everything you have learned so far. You will need to find your own dataset, do all the appropriate preprocessing, test different supervised learning models and evaluate the results. More details for each step can be found below.\n",
    "\n",
    "### You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b67a661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Imports for text processing tasks\n",
    "!pip install contractions > /dev/null\n",
    "import contractions\n",
    "import nltk # Imports the Natural Language Toolkit module\n",
    "import re # regex\n",
    "\n",
    "# Imports for pipelines, modeling, and evaluation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "## Step 1: Data Input (4 marks)\n",
    "\n",
    "Import the dataset you will be using. You can download the dataset onto your computer and read it in using pandas, or download it directly from the website. Answer the questions below about the dataset you selected. \n",
    "\n",
    "To find a dataset, you can use the resources listed in the notes. The dataset can be numerical, categorical, text-based or mixed. If you want help finding a particular dataset related to your interests, please email the instructor.\n",
    "\n",
    "**You cannot use a dataset that was used for a previous assignment or in class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af8bd32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import dataset (1 mark)\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# I selected 3 categories that I like out of the 20 because every run was taking a loooooong time\n",
    "# Note that because I am still using 3 categories, this is a multiclass classification problem\n",
    "selected_categories = [\n",
    "    'sci.electronics',   # Topics related to electronics\n",
    "    'sci.med',           # Topics related to medical sciences\n",
    "    'sci.space',         # Topics related to space science \n",
    "]\n",
    "\n",
    "# Fetch only data for the selected topics\n",
    "newsgroups = fetch_20newsgroups(subset='all', categories=selected_categories)\n",
    "posts, targets = [s.strip() for s in newsgroups.data], newsgroups.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20316765",
   "metadata": {},
   "source": [
    "### Questions (3 marks)\n",
    "\n",
    "1. (1 mark) What is the source of your dataset?\n",
    "1. (1 mark) Why did you pick this particular dataset?\n",
    "1. (1 mark) Was there anything challenging about finding a dataset that you wanted to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c5e654-18e1-4b21-ac06-a691fc043cc2",
   "metadata": {},
   "source": [
    "1. My dataset is from sklearn datasets.\n",
    "1. I picked this dataset because I wanted to practice implementing machine learning models for text-based data because soon I will be coding my own Amazon review sentiment analyser for my final project in the ensf 612 big data course using spark. However I also wanted to go one step ahead an do a multiclass classifier instead of a binary one.\n",
    "1. Yes. I looked at many text-based datasets but most of them were for sentimen analysis using twitter data, amazon data or wine data. I thought classifying news was cool. I also struggled because originally I downloaded the 20newsgroups from the web as a .tar file with 20 folders each containing hundreds of individual document type files for each news publication. Later on I realized I could simply import it from sklean. And If it wasn't for sklearn I would've given up using this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "## Step 2: Data Processing (5 marks)\n",
    "\n",
    "The next step is to process your data. Implement the following steps as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df26345d-1fa3-4ef0-a137-a71100615bfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download necessary NLTK resources to process Text Data                   \n",
    "_ = nltk.download('punkt', quiet=True)           # Downloads a pre-trained tokenizer models used to split sentences\n",
    "_ = nltk.download('stopwords', quiet=True)       # Downloads a set of stopwords\n",
    "_ = nltk.download('wordnet', quiet=True)         # Downloads a lexical database of English, used for lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc244d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean data (if needed)\n",
    "\n",
    "# Custom transformer for word expansion\n",
    "class WordExpander(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [contractions.fix(text) for text in X]\n",
    "\n",
    "# Custom transformer for text cleaning\n",
    "class TextCleaning(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [re.sub(r'[^\\w\\s]', '', text.replace(\"'s\", \"\")) for text in X]\n",
    "\n",
    "# Custom transformer for tokenization\n",
    "class Tokenizer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [nltk.word_tokenize(text) for text in X]\n",
    "\n",
    "# Custom transformer for stop word removal\n",
    "class StopwordRemover(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "        return [[word for word in tokens if word.lower() not in stop_words] for tokens in X]\n",
    "\n",
    "# Custom transformer for lemmatization\n",
    "class Lemmatizer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "        return [' '.join([lemmatizer.lemmatize(word) for word in tokens]) for tokens in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70a8c127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implement preprocessing steps. Remember to use ColumnTransformer if more than one preprocessing method is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5eec58-735b-4504-83be-8a9967df1e84",
   "metadata": {},
   "source": [
    "Note: I did not use a column transformer because my dataset contains a single column and single type of data (text data). Thus all the preprocessing transformations are apply to the same single column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92c46b7",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "\n",
    "1. (1 mark) Were there any missing/null values in your dataset? If yes, how did you replace them and why? If no, describe how you would've replaced them and why.\n",
    "2. (1 mark) What type of data do you have? What preprocessing methods would you have to apply based on your data types?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f3b8ae-27db-4fdf-a2a5-3cee44aede5d",
   "metadata": {},
   "source": [
    "1. Since this dataset is simply an array or list of posts (text data). This dataset does not contain \"missing values\" in the tradional sense. For this specific dataset the posts either exists or does not exist. However if the datset were a table or dataframe containing features in addition of the text data, then in that case I would need to fill in the missing values or remove the rows or columns missing a significant amount of data.\n",
    "2. I have text based data. Each sample is a post and the target is a label of the topic of the post belongs to. As preprocessing steps I would have to apply text cleaning, tokenization, stop word removal, stemming or lemmatization and convert the text data into numerical data the computer can understand either using the world of bags strategy or TD-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "## Step 3: Implement Machine Learning Model (11 marks)\n",
    "\n",
    "In this section, you will implement three different supervised learning models (one linear and two non-linear) of your choice. You will use a pipeline to help you decide which model and hyperparameters work best. It is up to you to select what models to use and what hyperparameters to test. You can use the class examples for guidance. You must print out the best model parameters and results after the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12972f2c-c06f-4fa9-8d0e-f3d6a890704d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports for supervised learning classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(posts, targets, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5558a776",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Overall Estimator: Pipeline(steps=[('word_expander', WordExpander()),\n",
      "                ('text_cleaning', TextCleaning()), ('tokenizer', Tokenizer()),\n",
      "                ('stopword_remover', StopwordRemover()),\n",
      "                ('lemmatizer', Lemmatizer()),\n",
      "                ('vectorizer', TfidfVectorizer(max_features=5000)),\n",
      "                ('classifier',\n",
      "                 LogisticRegression(C=10, max_iter=5000, solver='liblinear'))])\n",
      "\n",
      "Best Overall Parameters: {'classifier': LogisticRegression(C=10, max_iter=5000, solver='liblinear'), 'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "\n",
      "Best average Cross-Validation F1 Score: 0.98\n",
      "\n",
      "Best average Cross-Validation Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Implement pipeline and grid search here. Can add more code blocks if necessary\n",
    "\n",
    "# Create a general pipeline with a placeholder for the classifier\n",
    "pipeline = Pipeline([\n",
    "    ('word_expander', WordExpander()),\n",
    "    ('text_cleaning', TextCleaning()),\n",
    "    ('tokenizer', Tokenizer()),\n",
    "    ('stopword_remover', StopwordRemover()),\n",
    "    ('lemmatizer', Lemmatizer()),\n",
    "    ('vectorizer', TfidfVectorizer(max_features=5000)),\n",
    "    ('classifier', None)  # Placeholder for the classifier\n",
    "])\n",
    "\n",
    "# Define a combined parameter grid\n",
    "param_grid = [\n",
    "    {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "     'classifier__C': [0.1, 1, 10],\n",
    "     'classifier__penalty': ['l1', 'l2'],\n",
    "     'classifier__solver': ['liblinear', 'saga']},\n",
    "    {'classifier': [MultinomialNB()],\n",
    "     'classifier__alpha': [0.1, 1, 10]},\n",
    "    {'classifier': [KNeighborsClassifier()],\n",
    "     'classifier__n_neighbors': [3, 5, 7],\n",
    "     'classifier__weights': ['uniform', 'distance']}\n",
    "]\n",
    "\n",
    "# Define scoring metrics for all classifiers\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1_score': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "# Create GridSearchCV instance\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=scoring, refit='f1_score')\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best model parameters \n",
    "print(\"Best Overall Estimator:\", grid_search.best_estimator_)\n",
    "print(\"\\nBest Overall Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best model results\n",
    "cv_results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "best_f1_score = cv_results_df.loc[grid_search.best_index_, 'mean_test_f1_score']\n",
    "print(f'\\nBest average Cross-Validation F1 Score: {best_f1_score:.2f}')\n",
    "\n",
    "best_accuracy = cv_results_df.loc[grid_search.best_index_, 'mean_test_accuracy']\n",
    "print(f'\\nBest average Cross-Validation Accuracy: {best_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38aceea-0d61-4e80-b138-7b7ff234b0e9",
   "metadata": {},
   "source": [
    "### Questions (5 marks)\n",
    "\n",
    "1. (1 mark) Do you need regression or classification models for your dataset?\n",
    "1. (2 marks) Which models did you select for testing and why?\n",
    "1. (2 marks) Which model worked the best? Does this make sense based on the theory discussed in the course and the context of your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6b1b33-20ae-4ed8-a9e8-e60840f2c422",
   "metadata": {},
   "source": [
    "1. I need classification models since I am trying to assign each news post a discret label corresponding to electronics, medical science or space science.\n",
    "1. I selected Logistic Regression because I had to choose 1 linear model, and because LogisticRegression is easy to implement and it is a good start specially for large datasets. I selected Multinomial Naive Bayes because several youtube videos mention NB as a standard and commonly used model for NPL because it treats the features independently and it makes it efficient for text data as the number of features is in the order of thousands. Finally I implemented K-Neighbors Classifier because we had not implemented yet in the previous assigments and since KNN works by comparing the position of features to its neighbors I thought KNN would be efficient for this classification problem.\n",
    "1. Logistic Regression worked the best. I think it makes sense Logistic Regression outperformed the other two models if the dataset features follow a straight line which I think it is what happened here and that's why I also obtained high F1 scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "## Step 4: Validate Model (6 marks)\n",
    "\n",
    "Use the testing set to calculate the testing accuracy for the best model determined in Step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69e64c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.98\n"
     ]
    }
   ],
   "source": [
    "# Calculate testing accuracy (1 mark)\n",
    "print(f'Test accuracy {grid_search.score(X_test, y_test):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4529ba",
   "metadata": {},
   "source": [
    "### Questions (5 marks)\n",
    "\n",
    "1. (1 mark) Which accuracy metric did you choose? \n",
    "1. (1 mark) How do these results compare to those in part 3? Did this model generalize well?\n",
    "1. (3 marks) Based on your results and the context of your dataset, did the best model perform \"well enough\" to be used out in the real-world? Why or why not? Do you have any suggestions for how you could improve this analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c8832-5f68-42dc-92e3-a76bd195ebd4",
   "metadata": {},
   "source": [
    "1. Because I am working with multiclass classification I chose F1 score with average='weighted'. This metric computes the F1 score for each class individually and then computes the weighted average based on the number of samples in each class. Although the 20newsgroups dataset is not an imbalaced dataset. I also decided to use F1 scores as a good practice since obtaining a good F1 score means that recall and precision are also high. Whereas only using accuracy can be misleading in imbalanced datasets. \n",
    "1. The testing accuracy of 0.98 score is very high and it matches the training accuracy score which is also 0.98. This means that the model is generalizing well in new unseen data. And at the same time it is not indicating overfitting or underfitting.\n",
    "1. Yes the model has high precision and recall and it is classifying almost all of the posts correctly. I think the model is well suited for the real world as long as the new posts follow a similar format and that of course the new posts belong to one of the 3 categories. I do not have any specific suggestion o how to improve the analysis. I think that trying to improve this model is uneccesary because the model is already performing quite well and doing more heavy tunning or using more complex models can be a waste of resources and may not even yield any significant improvements. I also think it can be risky as we might end up overfitting due to increased model complexity. Finally, although in general for linear models more features can be beneficial. My personal opinion is that instead of trying to improve the model I would look into reducing the number of features even further. Note that I already  tried to reduce the features setting my TfidfVectorizer to max_features=5000. But still my computer took 4 minutes to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "## Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "1. I sourced my code using code from my Amazon sentiment analysis review project using pyspark in ensf 612, specifically the part of how to do text pre-processing. And I also sourced my code from the pipelines examples on this course, especifically from the notebook Pipeline Steps.\n",
    "1. I first looked into several datasets, once I chose 20News I made some file exploration, then I looked into how to adapt my pyspark code using the modules of sparknlp.base and sparknlp.annotator to achieve the same using sklearn.base and ntlk modules in regular python. Finally I reviewed the pipeline example notebook to complete the pipeline portion of the assigment. \n",
    "1. I used several prompts for dataset brainstorming. I asked \"give examples of cool datasets for text data classification\". I also asked chatgpt how to modify my existing pyspark code and turn it into regular python to do all the preprocessing and it hinted me to use the TfidfVectorizer built in functionality to do all the preproccesing. But instead I decided to create my own costum transformers to practice further. \n",
    "1. Yes I had several challenges. First I struggle to get the 20News dataset because originally I was dealing with a huge .tar file until I realized I could import it from sklearn. Second I struggle a lot using nltk because it required a lot of modules and external resources to make it work. And my program crashed a lot of times and it was running very slow so I had to reduce the number of features. Finally bulding the pipeline and applying it with GridSearchCV was also a little bit challenging but not as much as the preprocessing. A lot of patience, my previous practice using text data in pyspark and the resources provided in this course helped me be succesful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challenging, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "I liked that we had the opportunity to work and learn on our own. I think I learnt a lot in this assigment, although it was also harder than the previous ones.\n",
    "What I dislike is that at the same time it was hard for me to come with my own dataset and I am not very imaginative.\n",
    "\n",
    "I found a lot of things challenging while working with text data. But I also liked it a lot and I would like to keep learning about AI and Natural language processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
